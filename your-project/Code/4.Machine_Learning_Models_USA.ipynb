{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Analysis USA:\n",
    "#### In this Jupyter Notebook you will find the process of exploratory Analysis of the file Clean_Insurance_USA.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa = pd.read_csv('../Data/Clean_data/Clean_Insurance_USA.csv', index_col=0) #dataframe saved in us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Customer', 'State', 'Coverage', 'Education', 'Job_Status', 'Gender',\n",
       "       'Income', 'Location', 'Civil_Status', 'Monthly_Price',\n",
       "       'Months_LastClaim', 'Months_SinceActivation', 'Number_Open_Complaints',\n",
       "       'Number_Insurances', 'Policy_Type', 'Sales_Channel', 'Car_Type',\n",
       "       'Car_Size'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usa.columns #Inspecting columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation of categorical data into boolean variables so that I can apply algorithms to it. I have decided to work with Civil_Status, Location, Policy_Type and Education because I think they are the treats that may influence having an accident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gender dummy\n",
    "dummy = pd.get_dummies(usa, columns = ['Civil_Status','Location', 'Policy_Type', 'Education'], drop_first = True)\n",
    "usa_dummy = pd.concat([usa,dummy], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number_Open_Complaints is the feature that we want to predict, it is expressed in how many accidents did that person had in the last year, but for simplification, I will translate that into whether a customer had 1 or more accidents (1) or not (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa['Number_Open_Complaints'] = usa.Number_Open_Complaints.apply(lambda x: 0 if x==0 else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate our data in train and test, to check if our predictions are right or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #importing library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test size of 0.2 and decided to use stratify to make sure the proportion of 0 and 1 in train and test is\n",
    "#the same, to avoid bias on splitting the dataset.\n",
    "X_train, X_test, y_train, y_test = train_test_split(usa_dummy[['Civil_Status_Married', 'Civil_Status_Single',\n",
    "                                                               'Location_Suburban', 'Location_Urban', \n",
    "                                                               'Policy_Type_Personal Auto',\n",
    "                                                               'Policy_Type_Special Auto', 'Education_College',\n",
    "                                                               'Education_Doctor','Education_High School or Below', \n",
    "                                                               'Education_Master']], \n",
    "                                                    usa[['Number_Open_Complaints']],\n",
    "                                                    test_size=0.2, stratify = usa[['Number_Open_Complaints']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Supervised Learning algorithms.\n",
    "This is a case of supervised learning since we are trying to predict one outcome that is on the dataset and hence, I will build algorithms that maximizes the number of True Positives, people that might have an accident, always looking at the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1451,    0],\n",
       "       [ 376,    0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, prediction) #All values are on the left (all Positives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREGUNTA A NACHO: Los positives son la gente que no tendrá accidente, no?\n",
    "#PCA se debería hacer al principio de todo, o más tarde?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.41981390257253"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "knn.fit(X_train, y_train.values.reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1296,  155],\n",
       "       [ 332,   44]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred) #More distributed values, but low accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.34428024083196"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test, y_test)*100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=6, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=6, metric='euclidean')\n",
    "knn.fit(X_train, y_train.values.reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1332,  119],\n",
       "       [ 337,   39]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.04105090311987"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test, y_test)*100 #Accuracy of 75%. Tested for 7 n_neighbors, went down to 71%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1230,  221],\n",
       "       [ 330,   46]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=6, metric='cosine')\n",
    "knn.fit(X_train, y_train.values.reshape(-1,))\n",
    "y_pred = knn.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred) #75 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.84126984126983"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test, y_test)*100 #Accuracy of 69% with different distance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(X_train, y_train.values.reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1451,    0],\n",
       "       [ 376,    0]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predi = svc.predict(X_test)\n",
    "confusion_matrix(y_test, y_predi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "ks_model = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1451,    0],\n",
       "       [ 376,    0]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = ks_model.predict(X_test)\n",
    "#y_pred_test\n",
    "confusion_matrix(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA \n",
    "  \n",
    "pca = PCA(n_components = 5) \n",
    "  \n",
    "X_train = pca.fit_transform(X_train) \n",
    "X_test = pca.transform(X_test) \n",
    "  \n",
    "explained_variance = pca.explained_variance_ratio_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.27254246, 0.18902251, 0.1643694 , 0.12513085, 0.08691207])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance #With these components, 83% of the variance is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression   \n",
    "  \n",
    "classifier = LogisticRegression(random_state = 0) \n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1451,    0],\n",
       "       [ 376,    0]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7307/7307 [==============================] - 3s 388us/step - loss: 0.5199 - accuracy: 0.7935\n",
      "Epoch 2/50\n",
      "7307/7307 [==============================] - 3s 368us/step - loss: 0.5139 - accuracy: 0.7939\n",
      "Epoch 3/50\n",
      "7307/7307 [==============================] - 3s 365us/step - loss: 0.5137 - accuracy: 0.7939\n",
      "Epoch 4/50\n",
      "7307/7307 [==============================] - 3s 363us/step - loss: 0.5122 - accuracy: 0.7939\n",
      "Epoch 5/50\n",
      "7307/7307 [==============================] - 3s 363us/step - loss: 0.5111 - accuracy: 0.7939\n",
      "Epoch 6/50\n",
      "7307/7307 [==============================] - 3s 364us/step - loss: 0.5102 - accuracy: 0.7939\n",
      "Epoch 7/50\n",
      "7307/7307 [==============================] - 3s 378us/step - loss: 0.5102 - accuracy: 0.7939\n",
      "Epoch 8/50\n",
      "7307/7307 [==============================] - 3s 409us/step - loss: 0.5098 - accuracy: 0.7939\n",
      "Epoch 9/50\n",
      "7307/7307 [==============================] - 3s 470us/step - loss: 0.5094 - accuracy: 0.7939\n",
      "Epoch 10/50\n",
      "7307/7307 [==============================] - 3s 442us/step - loss: 0.5090 - accuracy: 0.7939\n",
      "Epoch 11/50\n",
      "7307/7307 [==============================] - 5s 616us/step - loss: 0.5086 - accuracy: 0.7939\n",
      "Epoch 12/50\n",
      "7307/7307 [==============================] - 4s 534us/step - loss: 0.5082 - accuracy: 0.7939\n",
      "Epoch 13/50\n",
      "7307/7307 [==============================] - 6s 759us/step - loss: 0.5089 - accuracy: 0.7939\n",
      "Epoch 14/50\n",
      "7307/7307 [==============================] - 4s 484us/step - loss: 0.5077 - accuracy: 0.7939\n",
      "Epoch 15/50\n",
      "7307/7307 [==============================] - 3s 460us/step - loss: 0.5082 - accuracy: 0.79390s - loss: 0.504\n",
      "Epoch 16/50\n",
      "7307/7307 [==============================] - 3s 476us/step - loss: 0.5074 - accuracy: 0.7939\n",
      "Epoch 17/50\n",
      "7307/7307 [==============================] - 3s 387us/step - loss: 0.5073 - accuracy: 0.7939\n",
      "Epoch 18/50\n",
      "7307/7307 [==============================] - 3s 414us/step - loss: 0.5069 - accuracy: 0.7939\n",
      "Epoch 19/50\n",
      "7307/7307 [==============================] - 3s 396us/step - loss: 0.5068 - accuracy: 0.7939\n",
      "Epoch 20/50\n",
      "7307/7307 [==============================] - 3s 389us/step - loss: 0.5067 - accuracy: 0.7939\n",
      "Epoch 21/50\n",
      "7307/7307 [==============================] - 3s 383us/step - loss: 0.5064 - accuracy: 0.7939\n",
      "Epoch 22/50\n",
      "7307/7307 [==============================] - 3s 390us/step - loss: 0.5058 - accuracy: 0.7940\n",
      "Epoch 23/50\n",
      "7307/7307 [==============================] - 3s 380us/step - loss: 0.5058 - accuracy: 0.7942\n",
      "Epoch 24/50\n",
      "7307/7307 [==============================] - 3s 378us/step - loss: 0.5053 - accuracy: 0.7940\n",
      "Epoch 25/50\n",
      "7307/7307 [==============================] - 3s 387us/step - loss: 0.5056 - accuracy: 0.7939\n",
      "Epoch 26/50\n",
      "7307/7307 [==============================] - 3s 420us/step - loss: 0.5051 - accuracy: 0.7939\n",
      "Epoch 27/50\n",
      "7307/7307 [==============================] - 3s 367us/step - loss: 0.5048 - accuracy: 0.7942\n",
      "Epoch 28/50\n",
      "7307/7307 [==============================] - 3s 434us/step - loss: 0.5047 - accuracy: 0.7939\n",
      "Epoch 29/50\n",
      "7307/7307 [==============================] - 4s 483us/step - loss: 0.5050 - accuracy: 0.7942\n",
      "Epoch 30/50\n",
      "7307/7307 [==============================] - 3s 424us/step - loss: 0.5047 - accuracy: 0.7942\n",
      "Epoch 31/50\n",
      "7307/7307 [==============================] - 3s 377us/step - loss: 0.5042 - accuracy: 0.7938\n",
      "Epoch 32/50\n",
      "7307/7307 [==============================] - 3s 385us/step - loss: 0.5044 - accuracy: 0.7940\n",
      "Epoch 33/50\n",
      "7307/7307 [==============================] - 3s 399us/step - loss: 0.5050 - accuracy: 0.7939\n",
      "Epoch 34/50\n",
      "7307/7307 [==============================] - 3s 379us/step - loss: 0.5045 - accuracy: 0.7939\n",
      "Epoch 35/50\n",
      "7307/7307 [==============================] - 3s 380us/step - loss: 0.5038 - accuracy: 0.7943\n",
      "Epoch 36/50\n",
      "7307/7307 [==============================] - 3s 384us/step - loss: 0.5043 - accuracy: 0.7938\n",
      "Epoch 37/50\n",
      "7307/7307 [==============================] - 3s 385us/step - loss: 0.5039 - accuracy: 0.7939\n",
      "Epoch 38/50\n",
      "7307/7307 [==============================] - 3s 382us/step - loss: 0.5037 - accuracy: 0.7936\n",
      "Epoch 39/50\n",
      "7307/7307 [==============================] - 3s 427us/step - loss: 0.5041 - accuracy: 0.7938\n",
      "Epoch 40/50\n",
      "7307/7307 [==============================] - 4s 609us/step - loss: 0.5040 - accuracy: 0.7940\n",
      "Epoch 41/50\n",
      "7307/7307 [==============================] - 3s 473us/step - loss: 0.5035 - accuracy: 0.7940\n",
      "Epoch 42/50\n",
      "7307/7307 [==============================] - 3s 394us/step - loss: 0.5044 - accuracy: 0.7935\n",
      "Epoch 43/50\n",
      "7307/7307 [==============================] - 3s 380us/step - loss: 0.5040 - accuracy: 0.7940\n",
      "Epoch 44/50\n",
      "7307/7307 [==============================] - 3s 400us/step - loss: 0.5031 - accuracy: 0.7938\n",
      "Epoch 45/50\n",
      "7307/7307 [==============================] - 3s 402us/step - loss: 0.5037 - accuracy: 0.7942\n",
      "Epoch 46/50\n",
      "7307/7307 [==============================] - 3s 389us/step - loss: 0.5044 - accuracy: 0.7942\n",
      "Epoch 47/50\n",
      "7307/7307 [==============================] - 3s 381us/step - loss: 0.5036 - accuracy: 0.7942\n",
      "Epoch 48/50\n",
      "7307/7307 [==============================] - 3s 387us/step - loss: 0.5035 - accuracy: 0.79420s - loss: 0.5063 - ac\n",
      "Epoch 49/50\n",
      "7307/7307 [==============================] - 3s 390us/step - loss: 0.5037 - accuracy: 0.7938\n",
      "Epoch 50/50\n",
      "7307/7307 [==============================] - 3s 383us/step - loss: 0.5033 - accuracy: 0.7940\n",
      "Test loss: 0.529344087457422\n",
      "Test accuracy: 0.7941981554031372\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "accidents = Sequential()\n",
    "accidents.add(Dense(units=200, kernel_initializer='uniform', activation='relu', input_dim=10))\n",
    "accidents.add(Dense(units=100, kernel_initializer='uniform', activation='relu'))\n",
    "accidents.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "accidents.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "accidents.fit(X_train, y_train, batch_size=5, epochs=10)\n",
    "val_loss, val_acc = accidents.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {val_loss}')\n",
    "print(f'Test accuracy: {val_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imbalance classes Target tenga mas 1 que 0, stratify en el split test o sino con oversampling y undersampling\n",
    "#Overfitting confusion matrix para ver si predigo perfectamente o no --> Cross validation or k-folds para evitar oversampling\n",
    "#Probar otros modelos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
